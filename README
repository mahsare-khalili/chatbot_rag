# ðŸ“š RAG-Powered PDF Chatbot
Answer questions from your own PDFs using a local LLM (FLAN-T5), semantic search (FAISS), and intelligent fallback.



# === STRUCTURE OVERVIEW ===

project/
 â”œâ”€â”€ main.py                    # Main entry point. Tries vector + RAG, falls back if needed
 â”œâ”€â”€ configs/
 â”‚   â””â”€â”€ settings.py            # Central configuration (model names, paths, thresholds, etc.)
 â”œâ”€â”€ ingest/
 â”‚   â””â”€â”€ run_ingest.py          # Loads PDFs, chunks text, embeds via SentenceTransformer, saves to FAISS + metadata
 â”œâ”€â”€ retriever/
 â”‚   â””â”€â”€ langchain_retriever.py # Retrieves top-K relevant chunks using vector similarity search
 â”œâ”€â”€ models/
 â”‚   â””â”€â”€ langchain_qa.py        # Generates an answer using Flan-T5 from HuggingFace Transformers
 â”œâ”€â”€ fallback/
 â”‚   â”œâ”€â”€ wikipedia_fallback.py  # Fallback using Wikipedia (via wikipedia package)
 â”‚   â””â”€â”€ duckduckgo_fallback.py # Fallback using DuckDuckGo API (if enabled in settings)
 â”œâ”€â”€ utils/
 â”‚   â””â”€â”€ chunking.py            # Shared chunking logic (sliding windows, overlap, etc.)
 â”œâ”€â”€ pdfs/                      # Input directory for raw documents (PDFs)
 â”œâ”€â”€ vectorstore/
 â”‚   â”œâ”€â”€ index.faiss            # FAISS vector index file
 â”‚   â””â”€â”€ metadata.json          # Metadata for associated chunks (source doc, chunk ID, etc.)
 â”œâ”€â”€ requirements.txt           # Dependency list for Python environment
 â”œâ”€â”€ README.md                  # Project overview, usage, structure, and setup instructions
 â””â”€â”€ .env                       # (Optional) API keys or environment variables
